{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "import time\n",
    "import re\n",
    "import pyprind\n",
    "import requests\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from math import cos, pi, floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_horse_id(path: str) -> list:\n",
    "    \"\"\"\n",
    "    example use: horse_id_list = fetch_horse_id(r\"data_20200822/1_horse_id_data.pkl\")\n",
    "    remove duplicates in return\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    horse_id_list = pd.read_pickle(path)[\"horse_id_list\"]\n",
    "    for lst_of_lst in horse_id_list:\n",
    "        for lst in lst_of_lst:\n",
    "            for i in lst:\n",
    "                output.append(i)\n",
    "    return list(dict.fromkeys(output))\n",
    "\n",
    "def update_status(horse_id: str) -> None:\n",
    "    with open(\"status.txt\",\"a+\",encoding = 'utf-8') as txt:\n",
    "        txt.write(horse_id+\"\\n\")\n",
    "        \n",
    "def remove_scraped_id(horse_id_list: list) -> list:\n",
    "    \"\"\"\n",
    "    read status.txt and remove those already been successfully scraped\n",
    "    return a filtered horse_id_list for future loops\n",
    "    \"\"\"\n",
    "    with open(\"status.txt\",\"r\",encoding = 'utf-8') as txt:\n",
    "        status = txt.readlines()\n",
    "        status = [x.replace('\\n','') for x in status]\n",
    "    horse_id_list = [x for x in horse_id_list if x not in status]\n",
    "    return horse_id_list\n",
    "\n",
    "def parse_challenge(page):\n",
    "    \"\"\"\n",
    "    Parse a challenge given by mmi and mavat's web servers, forcing us to solve\n",
    "    some math stuff and send the result as a header to actually get the page.\n",
    "    This logic is pretty much copied from https://github.com/R3dy/jigsaw-rails/blob/master/lib/breakbot.rb\n",
    "    \"\"\"\n",
    "    top = page.split('<script>')[1].split('\\n')\n",
    "    challenge = top[1].split(';')[0].split('=')[1]\n",
    "    challenge_id = top[2].split(';')[0].split('=')[1]\n",
    "    return {'challenge': challenge, 'challenge_id': challenge_id, 'challenge_result': get_challenge_answer(challenge)}\n",
    "\n",
    "def telegram_bot_sendtext(bot_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Send telegram msg for my bot\n",
    "    \"\"\"\n",
    "    bot_token = '1172952527:AAGoM74Rx25DPBpmQhEwacs_AQ9GWI8Oybk'\n",
    "    chat_id = \"839266998\"\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + chat_id + '&parse_mode=Markdown&text=' + bot_message\n",
    "    requests.get(send_text)\n",
    "\n",
    "def get_challenge_answer(challenge):\n",
    "    \"\"\"\n",
    "    Solve the math part of the challenge and get the result\n",
    "    \"\"\"\n",
    "    arr = list(challenge)\n",
    "    last_digit = int(arr[-1])\n",
    "    arr.sort()\n",
    "    min_digit = int(arr[0])\n",
    "    subvar1 = (2 * int(arr[2])) + int(arr[1])\n",
    "    subvar2 = str(2 * int(arr[2])) + arr[1]\n",
    "    power = ((int(arr[0]) * 1) + 2) ** int(arr[1])\n",
    "    x = (int(challenge) * 3 + subvar1)\n",
    "    y = cos(pi * subvar1)\n",
    "    answer = x * y\n",
    "    answer -= power\n",
    "    answer += (min_digit - last_digit)\n",
    "    answer = str(int(floor(answer))) + subvar2\n",
    "    return answer\n",
    "    \n",
    "def make_hkjc_request(url: str) -> str:\n",
    "    headers = {'User-agent': 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1'}\n",
    "    with requests.Session() as s:\n",
    "        r = s.get(url, headers = headers)\n",
    "        if 'X-AA-Challenge' in r.text:\n",
    "            challenge = parse_challenge(r.text)\n",
    "            cookies = s.get(url, headers={\n",
    "                'X-AA-Challenge': challenge['challenge'],\n",
    "                'X-AA-Challenge-ID': challenge['challenge_id'],\n",
    "                'X-AA-Challenge-Result': challenge['challenge_result']\n",
    "            }).cookies  \n",
    "        else:\n",
    "            cookies = r.cookies\n",
    "\n",
    "        r = s.post(url, cookies = cookies)\n",
    "\n",
    "    return r.text\n",
    "    \n",
    "def scrape_horse_data(horse_id):\n",
    "    url = f\"https://racing.hkjc.com/racing/information/english/Horse/HorseSearch.aspx?HorseName=&SearchType=BrandNumber&BrandNumber={horse_id}\"\n",
    "    res = make_hkjc_request(url)\n",
    "    soup = BeautifulSoup(res, \"lxml\")\n",
    "    horse_nm = re.search(\"^[^\\(]+\",soup.find(\"td\", attrs = {\"class\":\"subsubheader\"}).get_text()).group().strip()\n",
    "    \n",
    "    # currently the response may only give records of 3 seasons - to solve this, we make another request if there is the \"all records option\" available\n",
    "    all_records_url = soup.find(\"table\", attrs = {\"align\":\"right\"})\n",
    "    if all_records_url != None:\n",
    "        all_records_url = \"https://racing.hkjc.com\" + all_records_url.find(\"a\", attrs = {\"href\": re.compile(\".+Option=1$\")})[\"href\"]\n",
    "        res = make_hkjc_request(all_records_url)\n",
    "        soup = BeautifulSoup(res, \"lxml\")\n",
    "\n",
    "    df_horse_profile = extract_horse_profile(res, horse_nm, horse_id)\n",
    "    df_race_history = extract_racing_history(soup, horse_nm, horse_id)\n",
    "    try:\n",
    "        df_vet = extract_vet_record(soup, horse_nm, horse_id)\n",
    "    except TypeError:\n",
    "        df_vet = pd.DataFrame(columns = ['Date', 'Details', 'Passed Date', 'Horse_name', 'Horse_code']) \n",
    "    except IndexError:\n",
    "        df_vet = pd.DataFrame(columns = ['Date', 'Details', 'Passed Date', 'Horse_name', 'Horse_code'])\n",
    "        \n",
    "    try:\n",
    "        df_trackwork = extract_trackwork_record(soup, horse_nm, horse_id)\n",
    "    except TypeError:\n",
    "        df_trackwork = pd.DataFrame(columns = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code'])\n",
    "    except IndexError:\n",
    "        df_trackwork = pd.DataFrame(columns = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code'])\n",
    "\n",
    "    return df_horse_profile, df_race_history, df_vet, df_trackwork\n",
    "\n",
    "\n",
    "def extract_horse_profile(res: str, horse_nm, horse_id) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract horse profile, require source html\n",
    "    \"\"\"\n",
    "    tables = pd.read_html(res)\n",
    "    df = pd.concat([tables[2][[0,2]],tables[3][[0,2]]])\n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reindex(df.index.drop(0))\n",
    "\n",
    "    df['Horse_nm'] = horse_nm\n",
    "    df[\"Horse_code\"] = horse_id\n",
    "    try:\n",
    "        df[[\"Country of Origin\",\"Age\"]] = df[\"Country of Origin / Age\"].str.split(\"/\", n=2, expand = True)\n",
    "    except KeyError:\n",
    "        df[\"Age\"] = \"Unknown\"\n",
    "        \n",
    "    df[\"Colour\"] = \"and\".join(df[\"Colour / Sex\"].iloc[0].split(\"/\")[:-1]).strip()\n",
    "    df[\"Sex\"] = df[\"Colour / Sex\"].iloc[0].split(\"/\")[-1].strip()\n",
    "    \n",
    "    standard_col = ['Country of Origin', 'Import Type', 'Owner', 'Sire', 'Dam',\n",
    "           'Dam\\'s Sire', 'Same Sire', 'Horse_nm', 'Horse_code', 'Colour', 'Sex', 'Age']\n",
    "    df = df[standard_col]\n",
    "    return df\n",
    "\n",
    "# racing history\n",
    "def extract_racing_history(soup, horse_nm, horse_id) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract racing history for the specific horse\n",
    "    \"\"\"\n",
    "    horsedata = soup.find('table',attrs = {\"class\":\"bigborder\"})\n",
    "    tables = pd.read_html(str(horsedata))\n",
    "    df_horse = tables[0]\n",
    "    df_horse.columns = df_horse.iloc[0]\n",
    "    df_horse = df_horse.reindex(df_horse.index.drop(0))\n",
    "    df_horse = df_horse.reset_index(drop=True)\n",
    "    index_list = df_horse[(df_horse[\"RaceIndex\"] == df_horse[\"RaceIndex\"]) & (df_horse[\"Dist.\"] == df_horse[\"G\"])].index\n",
    "    df_horse_list = []\n",
    "    hiearchy_list = []\n",
    "\n",
    "    for indexes in range(len(index_list)):\n",
    "        if indexes != len(index_list)-1:\n",
    "            df_horse_list.append(df_horse[index_list[indexes]+1:index_list[indexes+1]])\n",
    "            hiearchy_list.append(df_horse.iloc[index_list[indexes]][\"RaceIndex\"])\n",
    "        else:\n",
    "            df_horse_list.append(df_horse[index_list[indexes]+1:])\n",
    "            hiearchy_list.append(df_horse.iloc[index_list[indexes]][\"RaceIndex\"])\n",
    "\n",
    "    for i in range(0,len(df_horse_list)):\n",
    "        df_horse_list[i][\"Season\"] = hiearchy_list[i]\n",
    "\n",
    "        df_horse = pd.concat(df_horse_list)\n",
    "        df_horse = df_horse.reset_index(drop=True)\n",
    "    \n",
    "    df_horse[\"RC_Track_Course\"] = df_horse[\"RC/Track/Course\"]\n",
    "    df_horse = df_horse.drop(columns=[\"RC/Track/Course\"])\n",
    "    df_horse['Horse_name'] = horse_nm\n",
    "    df_horse[\"Horse_code\"] = horse_id\n",
    "    \n",
    "    return df_horse\n",
    "\n",
    "def extract_vet_record(soup, horse_nm, horse_id):\n",
    "    \"\"\"\n",
    "    extract veterinary records for the horse - does not exist for retired horses\n",
    "    \"\"\"\n",
    "    vet_record = soup.find(\"a\", attrs = {\"class\": \"table_eng_text\", \"href\": re.compile(\".+VeterinaryRecords.+\")})\n",
    "    vet_record_link = r\"https://racing.hkjc.com\" + vet_record[\"href\"]\n",
    "    vet_res = make_hkjc_request(vet_record_link)\n",
    "    tables = pd.read_html(vet_res)  \n",
    "    df_vet = tables[4]\n",
    "    df_vet[\"Horse_name\"] = horse_nm\n",
    "    df_vet[\"Horse_code\"] = horse_id\n",
    "    return df_vet\n",
    "\n",
    "def extract_trackwork_record(soup, horse_nm, horse_id): \n",
    "    \"\"\"\n",
    "    extract trackwork records for the horse - does not exist for retired horses\n",
    "    \"\"\"\n",
    "    tw_record = soup.find(\"a\", attrs = {\"class\": \"table_eng_text\", \"href\": re.compile(\".+Trackwork.+\")})\n",
    "    tw_record_link = r\"https://racing.hkjc.com\" + tw_record[\"href\"]\n",
    "    tw_res = make_hkjc_request(tw_record_link)\n",
    "    tables = pd.read_html(tw_res)  \n",
    "    df_tw = tables[4]\n",
    "    df_tw[\"Racecourse_track\"] = df_tw[\"Racecourse/Track\"]\n",
    "    df_tw[\"Horse_name\"] = horse_nm\n",
    "    df_tw[\"Horse_code\"] = horse_id\n",
    "    \n",
    "    standard_col = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code']\n",
    "    df_tw = df_tw[standard_col]\n",
    "    \n",
    "    return df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 24 horses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [########################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:04:11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0 horses.\n",
      "Total 0 horses.\n",
      "Total 0 horses.\n",
      "Total 0 horses.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    telegram_bot_sendtext(f\"Horse scraper program started at {str(datetime.now())}.\")\n",
    "    error_list = []\n",
    "    horse_id_list = fetch_horse_id(r\"data_20200822/1_horse_id_data.pkl\")\n",
    "    \n",
    "    #can put the below in a retry loop\n",
    "    for i in range(5):\n",
    "        horse_id_list = remove_scraped_id(horse_id_list) # remove scraped id from horse_id_list\n",
    "        print(f\"Total {str(len(horse_id_list))} horses.\")\n",
    "        bar = pyprind.ProgBar(len(horse_id_list))\n",
    "        status_int = 0\n",
    "        for horse_id in horse_id_list:\n",
    "            try:\n",
    "                # set col values\n",
    "                horse_profile_col = {'Country of Origin': 100,\n",
    "                 'Import Type': 20,\n",
    "                 'Owner': 200,\n",
    "                 'Sire': 100,\n",
    "                 'Dam': 100,\n",
    "                 \"Dam's Sire\": 200,\n",
    "                 'Same Sire': 500,\n",
    "                 'Horse_nm': 100,\n",
    "                 'Horse_code': 10,\n",
    "                 'Colour': 20,\n",
    "                 'Sex': 20,\n",
    "                 'Age': 10}\n",
    "                \n",
    "                race_history_col = {'RaceIndex': 100,\n",
    "                 'Pla.': 20,\n",
    "                 'Date': 50,\n",
    "                 'RC_Track_Course': 50,\n",
    "                 'Dist.': 50,\n",
    "                 'G': 20,\n",
    "                 'RaceClass': 10,\n",
    "                 'Dr': 100,\n",
    "                 'Rtg.': 20,\n",
    "                 'Trainer': 50,\n",
    "                 'Jockey': 50,\n",
    "                 'LBW': 100,\n",
    "                 'Win Odds': 50,\n",
    "                 'Act.Wt.': 50,\n",
    "                 'RunningPosition': 50,\n",
    "                 'Finish Time': 50,\n",
    "                 'Declar.Horse Wt.': 20,\n",
    "                 'Gear': 20,\n",
    "                 'VideoReplay': 50,\n",
    "                 'Season': 20,\n",
    "                 'Horse_name': 100,\n",
    "                 'Horse_code': 10}\n",
    "                \n",
    "                vet_col = {'Date': 20,\n",
    "                 'Details': 300,\n",
    "                 'Passed Date': 200,\n",
    "                 'Horse_name': 100,\n",
    "                 'Horse_code': 10}\n",
    "                \n",
    "                trackwork_col = {'Date': 20,\n",
    "                 'Type': 200,\n",
    "                 'Racecourse_track': 100,\n",
    "                 'Workouts': 200,\n",
    "                 'Gear': 20,\n",
    "                 'Horse_name': 100,\n",
    "                 'Horse_code': 10}\n",
    "\n",
    "                # scrape data for the horse_id\n",
    "                df_horse_profile, df_race_history, df_vet, df_trackwork = scrape_horse_data(horse_id)\n",
    "                # write to hd5 -> hd5 defaults to append mode\n",
    "                df_horse_profile.to_hdf(r\"data_20200822\\horse_profile.h5\", key = \"df_horse_profile\", append = True, format = \"table\", min_itemsize = horse_profile_col)\n",
    "                df_race_history.to_hdf(r\"data_20200822\\race_history.h5\", key = \"df_race_history\", append = True, format = \"table\", min_itemsize = race_history_col)\n",
    "                df_vet.to_hdf(r\"data_20200822\\vet_record.h5\", key = \"df_vet\", append = True, format = \"table\", min_itemsize = vet_col)\n",
    "                df_trackwork.to_hdf(r\"data_20200822\\trackwork_record.h5\", key = \"df_trackwork\", append = True, format = \"table\", min_itemsize = trackwork_col)\n",
    "\n",
    "                # report status to telegram\n",
    "                if status_int % 500 == 0 and status_int > 0:\n",
    "                    telegram_bot_sendtext(f\"Completed {str(status_int)} out of {str(len(horse_id_list))} at {str(datetime.now())} with {len(error_list)} errors.\")\n",
    "\n",
    "                # update status\n",
    "                status_int +=1\n",
    "                update_status(horse_id)\n",
    "                bar.update()\n",
    "\n",
    "            except Exception as e:\n",
    "                status_int +=1\n",
    "                print(f\"{horse_id}: {str(e)}\")\n",
    "                error_list.append((horse_id, str(e)))\n",
    "\n",
    "        telegram_bot_sendtext(f\"Horse scraper program completed at {str(datetime.now())}, loop_ref: {str(i)}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
