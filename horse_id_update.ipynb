{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from typing import Dict, List\n",
    "import pyprind\n",
    "from math import cos, pi, floor\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parse_challenge(page):\n",
    "    \"\"\"\n",
    "    Parse a challenge given by mmi and mavat's web servers, forcing us to solve\n",
    "    some math stuff and send the result as a header to actually get the page.\n",
    "    This logic is pretty much copied from https://github.com/R3dy/jigsaw-rails/blob/master/lib/breakbot.rb\n",
    "    \"\"\"\n",
    "    top = page.split('<script>')[1].split('\\n')\n",
    "    challenge = top[1].split(';')[0].split('=')[1]\n",
    "    challenge_id = top[2].split(';')[0].split('=')[1]\n",
    "    return {'challenge': challenge, 'challenge_id': challenge_id, 'challenge_result': get_challenge_answer(challenge)}\n",
    "\n",
    "def telegram_bot_sendtext(bot_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Send telegram msg for my bot\n",
    "    \"\"\"\n",
    "    bot_token = '1172952527:AAGoM74Rx25DPBpmQhEwacs_AQ9GWI8Oybk'\n",
    "    chat_id = \"839266998\"\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + chat_id + '&parse_mode=Markdown&text=' + bot_message\n",
    "    requests.get(send_text)\n",
    "\n",
    "def get_challenge_answer(challenge):\n",
    "    \"\"\"\n",
    "    Solve the math part of the challenge and get the result\n",
    "    \"\"\"\n",
    "    arr = list(challenge)\n",
    "    last_digit = int(arr[-1])\n",
    "    arr.sort()\n",
    "    min_digit = int(arr[0])\n",
    "    subvar1 = (2 * int(arr[2])) + int(arr[1])\n",
    "    subvar2 = str(2 * int(arr[2])) + arr[1]\n",
    "    power = ((int(arr[0]) * 1) + 2) ** int(arr[1])\n",
    "    x = (int(challenge) * 3 + subvar1)\n",
    "    y = cos(pi * subvar1)\n",
    "    answer = x * y\n",
    "    answer -= power\n",
    "    answer += (min_digit - last_digit)\n",
    "    answer = str(int(floor(answer))) + subvar2\n",
    "    return answer\n",
    "\n",
    "def get_racing_days(df: pd.DataFrame) -> List:\n",
    "    \"\"\"\n",
    "    filter wednesday, saturday and sundays\n",
    "    filter non-august\n",
    "    \"\"\"\n",
    "    datelist = pd.date_range(\"2020/09/01\", datetime.now()).tolist()\n",
    "    datelist = [x.strftime(\"%Y/%m/%d\") for x in datelist if x.dayofweek in (2,5,6) and x.month != 8]\n",
    "\n",
    "    # remove existing dates\n",
    "    datelist = [x for x in datelist if x not in list(df[\"date\"])]\n",
    "    \n",
    "    return datelist\n",
    "\n",
    "def make_hkjc_request(url: str) -> str:\n",
    "    headers = {'User-agent': 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1'}\n",
    "    with requests.Session() as s:\n",
    "        r = s.get(url, headers = headers)\n",
    "        if 'X-AA-Challenge' in r.text:\n",
    "            challenge = parse_challenge(r.text)\n",
    "            cookies = s.get(url, headers={\n",
    "                'X-AA-Challenge': challenge['challenge'],\n",
    "                'X-AA-Challenge-ID': challenge['challenge_id'],\n",
    "                'X-AA-Challenge-Result': challenge['challenge_result']\n",
    "            }).cookies  \n",
    "        else:\n",
    "            cookies = r.cookies\n",
    "\n",
    "        r = s.post(url, cookies = cookies)\n",
    "\n",
    "    return r.text\n",
    "\n",
    "def evaluate_course(title):\n",
    "    clean_title = title.replace(\" \",\"\").lower()\n",
    "    if \"shatin\" in clean_title:\n",
    "        return \"ST\"\n",
    "    \n",
    "    elif \"happyvalley\" in clean_title:\n",
    "        return \"HV\"\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def scrape_race_day(date) -> Dict:\n",
    "    html_list = []\n",
    "    # first race\n",
    "    url = f\"https://racing.hkjc.com/racing/information/english/Racing/LocalResults.aspx?RaceDate={date}\"\n",
    "    first_race = make_hkjc_request(url)\n",
    "    soup = BeautifulSoup(first_race, \"lxml\")\n",
    "    html_list.append(soup)\n",
    "\n",
    "    # extract info\n",
    "    num_of_races = len(soup.find(\"table\", attrs = {\"class\": re.compile(\"f_fs12.+racecard$\")}).find_all(\"a\"))\n",
    "    course = evaluate_course(str(soup.find(\"span\", attrs = {\"class\": \"f_fl f_fs13\"})))\n",
    "    overhead_text = soup.find(\"tr\", attrs = {\"class\": re.compile(\"bg_blue.+font_wb$\")}).get_text()\n",
    "    first_race_no = re.search(\"\\((\\d+)\\)\", overhead_text).group(1)\n",
    "\n",
    "    # extract info for all other races and append to html_list\n",
    "    for i in range(2, num_of_races + 1):\n",
    "        url = f\"https://racing.hkjc.com/racing/information/english/Racing/LocalResults.aspx?RaceDate={date}&Racecourse={course}&RaceNo={str(i)}\"\n",
    "        race_info = make_hkjc_request(url)\n",
    "        soup = BeautifulSoup(race_info, \"lxml\")\n",
    "        html_list.append(soup)\n",
    "\n",
    "    # get horse_id_list\n",
    "    horse_id_list = []\n",
    "    for soup in html_list:\n",
    "        try:\n",
    "            single_race_id_list = list(pd.read_html(str(soup.find(\"div\", attrs = {\"class\": \"performance\"})))[0][\"Horse\"])\n",
    "            single_race_id_list = [re.search(\"\\(([\\w\\d]+)\\)\", x).group(1) for x in single_race_id_list]\n",
    "            horse_id_list.append(single_race_id_list)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    result_dict = {\n",
    "        \"date\": date,\n",
    "        \"first_race_no\": first_race_no,\n",
    "        \"horse_id_list\": horse_id_list    \n",
    "    }\n",
    "\n",
    "    return result_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [####] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:00:10\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    Just run this and it should automatically update all horse_id and racing days to the latest for 2020 season\n",
    "    \"\"\"\n",
    "    \n",
    "    # original horse_id_data\n",
    "    df = pd.read_pickle(r\"2020_season\\1_horse_id_data.pkl\")\n",
    "\n",
    "    # remove duplicated racing days\n",
    "    date_list = get_racing_days(df)\n",
    "\n",
    "    bar = pyprind.ProgBar(len(date_list))\n",
    "    for race_date in date_list:\n",
    "        try:\n",
    "            df_dict = scrape_race_day(race_date)\n",
    "            df = df.append(df_dict, ignore_index = True)\n",
    "            bar.update()\n",
    "        except AttributeError:\n",
    "            bar.update()\n",
    "            pass\n",
    "\n",
    "    df.to_pickle(r\"2020_season\\1_horse_id_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
