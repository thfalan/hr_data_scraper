{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from pandas import HDFStore\n",
    "import time\n",
    "import re\n",
    "import pyprind\n",
    "import requests\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from math import cos, pi, floor\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_horse_id(engine) -> list:\n",
    "    \"\"\"\n",
    "    fetch dataset from SQL with engine as input\n",
    "    name fixed as \"horse_id_data\"\n",
    "    remove duplicates in return\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(\"select * from horse_id_data\", con = engine)\n",
    "    \n",
    "    with open(\"race_dates.txt\", \"r\") as f:\n",
    "        date_list = f.readlines()\n",
    "        date_list = [x.replace(\"\\n\", \"\") for x in date_list]\n",
    "        \n",
    "    # remove scraped race dates\n",
    "    df = df[~df[\"date\"].isin(date_list)] #date is not in date_list - '~' means the opposite\n",
    "    output = []\n",
    "    horse_id_list = df[\"horse_id_list\"]\n",
    "    date_list = df[\"date\"]\n",
    "    for lst_of_lst in horse_id_list:\n",
    "        for lst in lst_of_lst:\n",
    "            for i in lst:\n",
    "                output.append(i)\n",
    "    return date_list, list(dict.fromkeys(output))\n",
    "\n",
    "def update_status(date_list: str) -> None:\n",
    "    for dt in date_list:\n",
    "        with open(\"race_dates.txt\",\"a+\",encoding = 'utf-8') as txt:\n",
    "            txt.write(dt +\"\\n\")\n",
    "        \n",
    "def remove_scraped_id(horse_id_list: list) -> list:\n",
    "    \"\"\"\n",
    "    read status.txt and remove those already been successfully scraped\n",
    "    return a filtered horse_id_list for future loops\n",
    "    \"\"\"\n",
    "    with open(\"updater_status.txt\",\"r\",encoding = 'utf-8') as txt:\n",
    "        status = txt.readlines()\n",
    "        status = [x.replace('\\n','') for x in status]\n",
    "    horse_id_list = [x for x in horse_id_list if x not in status]\n",
    "    return horse_id_list\n",
    "\n",
    "def parse_challenge(page):\n",
    "    \"\"\"\n",
    "    Parse a challenge given by mmi and mavat's web servers, forcing us to solve\n",
    "    some math stuff and send the result as a header to actually get the page.\n",
    "    This logic is pretty much copied from https://github.com/R3dy/jigsaw-rails/blob/master/lib/breakbot.rb\n",
    "    \"\"\"\n",
    "    top = page.split('<script>')[1].split('\\n')\n",
    "    challenge = top[1].split(';')[0].split('=')[1]\n",
    "    challenge_id = top[2].split(';')[0].split('=')[1]\n",
    "    return {'challenge': challenge, 'challenge_id': challenge_id, 'challenge_result': get_challenge_answer(challenge)}\n",
    "\n",
    "def telegram_bot_sendtext(bot_message: str) -> None:\n",
    "    \"\"\"\n",
    "    Send telegram msg for my bot\n",
    "    \"\"\"\n",
    "    bot_token = '1172952527:AAGoM74Rx25DPBpmQhEwacs_AQ9GWI8Oybk'\n",
    "    chat_id = \"839266998\"\n",
    "    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + chat_id + '&parse_mode=Markdown&text=' + bot_message\n",
    "    requests.get(send_text)\n",
    "\n",
    "def get_challenge_answer(challenge):\n",
    "    \"\"\"\n",
    "    Solve the math part of the challenge and get the result\n",
    "    \"\"\"\n",
    "    arr = list(challenge)\n",
    "    last_digit = int(arr[-1])\n",
    "    arr.sort()\n",
    "    min_digit = int(arr[0])\n",
    "    subvar1 = (2 * int(arr[2])) + int(arr[1])\n",
    "    subvar2 = str(2 * int(arr[2])) + arr[1]\n",
    "    power = ((int(arr[0]) * 1) + 2) ** int(arr[1])\n",
    "    x = (int(challenge) * 3 + subvar1)\n",
    "    y = cos(pi * subvar1)\n",
    "    answer = x * y\n",
    "    answer -= power\n",
    "    answer += (min_digit - last_digit)\n",
    "    answer = str(int(floor(answer))) + subvar2\n",
    "    return answer\n",
    "    \n",
    "def make_hkjc_request(url: str) -> str:\n",
    "    headers = {'User-agent': 'Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1'}\n",
    "    with requests.Session() as s:\n",
    "        r = s.get(url, headers = headers)\n",
    "        if 'X-AA-Challenge' in r.text:\n",
    "            challenge = parse_challenge(r.text)\n",
    "            cookies = s.get(url, headers={\n",
    "                'X-AA-Challenge': challenge['challenge'],\n",
    "                'X-AA-Challenge-ID': challenge['challenge_id'],\n",
    "                'X-AA-Challenge-Result': challenge['challenge_result']\n",
    "            }).cookies  \n",
    "        else:\n",
    "            cookies = r.cookies\n",
    "\n",
    "        r = s.post(url, cookies = cookies)\n",
    "\n",
    "    return r.text\n",
    "    \n",
    "def scrape_horse_data(horse_id):\n",
    "    url = f\"https://racing.hkjc.com/racing/information/english/Horse/HorseSearch.aspx?HorseName=&SearchType=BrandNumber&BrandNumber={horse_id}\"\n",
    "    res = make_hkjc_request(url)\n",
    "    soup = BeautifulSoup(res, \"lxml\")\n",
    "    horse_nm = re.search(\"^[^\\(]+\",soup.find(\"td\", attrs = {\"class\":\"subsubheader\"}).get_text()).group().strip()\n",
    "    \n",
    "    # currently the response may only give records of 3 seasons - to solve this, we make another request if there is the \"all records option\" available\n",
    "    all_records_url = soup.find(\"table\", attrs = {\"align\":\"right\"})\n",
    "    if all_records_url != None:\n",
    "        all_records_url = \"https://racing.hkjc.com\" + all_records_url.find(\"a\", attrs = {\"href\": re.compile(\".+Option=1$\")})[\"href\"]\n",
    "        res = make_hkjc_request(all_records_url)\n",
    "        soup = BeautifulSoup(res, \"lxml\")\n",
    "\n",
    "    df_horse_profile = extract_horse_profile(res, horse_nm, horse_id)\n",
    "    df_race_history = extract_racing_history(soup, horse_nm, horse_id)\n",
    "    try:\n",
    "        df_vet = extract_vet_record(soup, horse_nm, horse_id)\n",
    "    except TypeError:\n",
    "        df_vet = pd.DataFrame(columns = ['Date', 'Details', 'Passed Date', 'Horse_name', 'Horse_code']) \n",
    "    except IndexError:\n",
    "        df_vet = pd.DataFrame(columns = ['Date', 'Details', 'Passed Date', 'Horse_name', 'Horse_code'])\n",
    "        \n",
    "    try:\n",
    "        df_trackwork = extract_trackwork_record(soup, horse_nm, horse_id)\n",
    "    except TypeError:\n",
    "        df_trackwork = pd.DataFrame(columns = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code'])\n",
    "    except IndexError:\n",
    "        df_trackwork = pd.DataFrame(columns = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code'])\n",
    "\n",
    "    return df_horse_profile, df_race_history, df_vet, df_trackwork\n",
    "\n",
    "\n",
    "def extract_horse_profile(res: str, horse_nm, horse_id) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract horse profile, require source html\n",
    "    \"\"\"\n",
    "    tables = pd.read_html(res)\n",
    "    df = pd.concat([tables[2][[0,2]],tables[3][[0,2]]])\n",
    "    df = df.transpose()\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.reindex(df.index.drop(0))\n",
    "\n",
    "    df['Horse_nm'] = horse_nm\n",
    "    df[\"Horse_code\"] = horse_id\n",
    "    df['snapshot_date'] = pd.to_datetime(datetime.now())\n",
    "    try:\n",
    "        df[[\"Country of Origin\",\"Age\"]] = df[\"Country of Origin / Age\"].str.split(\"/\", n=2, expand = True)\n",
    "    except KeyError:\n",
    "        df[\"Age\"] = \"Unknown\"\n",
    "        \n",
    "    df[\"Colour\"] = \"and\".join(df[\"Colour / Sex\"].iloc[0].split(\"/\")[:-1]).strip()\n",
    "    df[\"Sex\"] = df[\"Colour / Sex\"].iloc[0].split(\"/\")[-1].strip()\n",
    "    \n",
    "    standard_col = ['snapshot_date', 'Country of Origin', 'Import Type', 'Owner', 'Sire', 'Dam',\n",
    "           'Dam\\'s Sire', 'Same Sire', 'Horse_nm', 'Horse_code', 'Colour', 'Sex', 'Age']\n",
    "    df = df[standard_col]\n",
    "    return df\n",
    "\n",
    "# racing history\n",
    "def extract_racing_history(soup, horse_nm, horse_id) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract racing history for the specific horse\n",
    "    \"\"\"\n",
    "    horsedata = soup.find('table',attrs = {\"class\":\"bigborder\"})\n",
    "    tables = pd.read_html(str(horsedata))\n",
    "    df_horse = tables[0]\n",
    "    df_horse.columns = df_horse.iloc[0]\n",
    "    df_horse = df_horse.reindex(df_horse.index.drop(0))\n",
    "    df_horse = df_horse.reset_index(drop=True)\n",
    "    index_list = df_horse[(df_horse[\"RaceIndex\"] == df_horse[\"RaceIndex\"]) & (df_horse[\"Dist.\"] == df_horse[\"G\"])].index\n",
    "    df_horse_list = []\n",
    "    hiearchy_list = []\n",
    "\n",
    "    for indexes in range(len(index_list)):\n",
    "        if indexes != len(index_list)-1:\n",
    "            df_horse_list.append(df_horse[index_list[indexes]+1:index_list[indexes+1]])\n",
    "            hiearchy_list.append(df_horse.iloc[index_list[indexes]][\"RaceIndex\"])\n",
    "        else:\n",
    "            df_horse_list.append(df_horse[index_list[indexes]+1:])\n",
    "            hiearchy_list.append(df_horse.iloc[index_list[indexes]][\"RaceIndex\"])\n",
    "\n",
    "    for i in range(0,len(df_horse_list)):\n",
    "        df_horse_list[i][\"Season\"] = hiearchy_list[i]\n",
    "\n",
    "        df_horse = pd.concat(df_horse_list)\n",
    "        df_horse = df_horse.reset_index(drop=True)\n",
    "    \n",
    "    df_horse[\"RC_Track_Course\"] = df_horse[\"RC/Track/Course\"]\n",
    "    df_horse = df_horse.drop(columns=[\"RC/Track/Course\"])\n",
    "    df_horse['Horse_name'] = horse_nm\n",
    "    df_horse[\"Horse_code\"] = horse_id\n",
    "    \n",
    "    return df_horse\n",
    "\n",
    "def extract_vet_record(soup, horse_nm, horse_id):\n",
    "    \"\"\"\n",
    "    extract veterinary records for the horse - does not exist for retired horses\n",
    "    \"\"\"\n",
    "    vet_record = soup.find(\"a\", attrs = {\"class\": \"table_eng_text\", \"href\": re.compile(\".+VeterinaryRecords.+\")})\n",
    "    vet_record_link = r\"https://racing.hkjc.com\" + vet_record[\"href\"]\n",
    "    vet_res = make_hkjc_request(vet_record_link)\n",
    "    tables = pd.read_html(vet_res)  \n",
    "    df_vet = tables[4]\n",
    "    df_vet[\"Horse_name\"] = horse_nm\n",
    "    df_vet[\"Horse_code\"] = horse_id\n",
    "    return df_vet\n",
    "\n",
    "def extract_trackwork_record(soup, horse_nm, horse_id): \n",
    "    \"\"\"\n",
    "    extract trackwork records for the horse - does not exist for retired horses\n",
    "    \"\"\"\n",
    "    tw_record = soup.find(\"a\", attrs = {\"class\": \"table_eng_text\", \"href\": re.compile(\".+Trackwork.+\")})\n",
    "    tw_record_link = r\"https://racing.hkjc.com\" + tw_record[\"href\"]\n",
    "    tw_res = make_hkjc_request(tw_record_link)\n",
    "    tables = pd.read_html(tw_res)  \n",
    "    df_tw = tables[4]\n",
    "    df_tw[\"Racecourse_track\"] = df_tw[\"Racecourse/Track\"]\n",
    "    df_tw[\"Horse_name\"] = horse_nm\n",
    "    df_tw[\"Horse_code\"] = horse_id\n",
    "    \n",
    "    standard_col = ['Date', 'Type', 'Racecourse_track', 'Workouts', 'Gear', 'Horse_name', 'Horse_code']\n",
    "    df_tw = df_tw[standard_col]\n",
    "    \n",
    "    return df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 89 horses.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0% [##############################] 100% | ETA: 00:00:00\n",
      "Total time elapsed: 00:11:04\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f8c2d70bc674>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mupdate_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mtelegram_bot_sendtext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Horse scraper program completed at {str(datetime.now())}, loop_ref: {str(i)}.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # assuming port forwarded to 9001\n",
    "    engine = sqlalchemy.create_engine('postgresql://postgres:postgres@localhost:9001/horse_racing')\n",
    "    \n",
    "    telegram_bot_sendtext(f\"Horse scraper program started at {str(datetime.now())}.\")\n",
    "    error_list = []\n",
    "    date_list, horse_id_list = fetch_horse_id(engine)\n",
    "    \n",
    "    #can put the below in a retry loop\n",
    "    print(f\"Total {str(len(horse_id_list))} horses.\")\n",
    "    bar = pyprind.ProgBar(len(horse_id_list))\n",
    "    status_int = 0\n",
    "    for horse_id in horse_id_list:\n",
    "        try:\n",
    "  \n",
    "            # scrape data for the horse_id\n",
    "            df_horse_profile, df_race_history, df_vet, df_trackwork = scrape_horse_data(horse_id)\n",
    "            # write to sql - append mode + multi\n",
    "            \n",
    "            df_horse_profile.to_sql(r\"horse_profile\", if_exists = 'append', con = engine, method = 'multi')\n",
    "            df_race_history.to_sql(r\"race_history\", if_exists = 'append', con = engine, method = 'multi')\n",
    "            df_vet.to_sql(r\"vet_record\", if_exists = 'append', con = engine, method = 'multi')\n",
    "            df_trackwork.to_sql(r\"trackwork_record\", if_exists = 'append', con = engine, method = 'multi')\n",
    "\n",
    "            # report status to telegram\n",
    "            if status_int % 500 == 0 and status_int > 0:\n",
    "                telegram_bot_sendtext(f\"Completed {str(status_int)} out of {str(len(horse_id_list))} at {str(datetime.now())} with {len(error_list)} errors.\")\n",
    "\n",
    "            # update status\n",
    "            status_int +=1\n",
    "            bar.update()\n",
    "\n",
    "        except Exception as e:\n",
    "            status_int +=1\n",
    "            print(f\"{horse_id}: {str(e)}\")\n",
    "            error_list.append((horse_id, str(e)))\n",
    "            \n",
    "    # update status if there are no errors\n",
    "    if len(error_list) == 0:\n",
    "        update_status(date_list)\n",
    "\n",
    "    telegram_bot_sendtext(f\"Horse scraper program completed at {str(datetime.now())}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
